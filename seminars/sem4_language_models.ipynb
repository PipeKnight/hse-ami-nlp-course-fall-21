{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "sem4_language_models.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8gF119Ux1HaY",
        "fC8XCdrZ1Hcg",
        "1E1tAyYU1HeP"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnzqMx3W1HAe"
      },
      "source": [
        "# Language modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzkNxXTj1HAu"
      },
      "source": [
        "\n",
        "Обучим две различные символьные модели для генерации динозавров:\n",
        "* модель на символьных биграммах\n",
        "* ***RNN***-модель.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHVEAXRs1HA6"
      },
      "source": [
        "## Bigram model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtIM9SS81HBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11a0e0e6-54e2-4065-ea11-4865eaae4664"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/artemovae/NLP-seminar-LM/master/dinos.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-22 19:09:11--  https://raw.githubusercontent.com/artemovae/NLP-seminar-LM/master/dinos.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19909 (19K) [text/plain]\n",
            "Saving to: ‘dinos.txt’\n",
            "\n",
            "\rdinos.txt             0%[                    ]       0  --.-KB/s               \rdinos.txt           100%[===================>]  19.44K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-09-22 19:09:12 (47.0 MB/s) - ‘dinos.txt’ saved [19909/19909]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6iUdpaO1HCO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd42002c-2813-4401-a5a7-20c947f543a6"
      },
      "source": [
        "!cat dinos.txt | tail"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zhuchengtyrannus\n",
            "Ziapelta\n",
            "Zigongosaurus\n",
            "Zizhongosaurus\n",
            "Zuniceratops\n",
            "Zunityrannus\n",
            "Zuolong\n",
            "Zuoyunlong\n",
            "Zupaysaurus\n",
            "Zuul"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8bDbP7V1HC_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f5b9929-b355-477d-c214-3ea5c2241d31"
      },
      "source": [
        "names = ['<' + name.strip().lower() + '>' for name in open('dinos.txt').readlines()]\n",
        "print(names[:10])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<aachenosaurus>', '<aardonyx>', '<abdallahsaurus>', '<abelisaurus>', '<abrictosaurus>', '<abrosaurus>', '<abydosaurus>', '<acanthopholis>', '<achelousaurus>', '<acheroraptor>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbECrMSs1HDn"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0FvBchI1HEI"
      },
      "source": [
        "Вычислим частоту каждого символа в корпусе имен динозавров"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rFk6yvK1HEN"
      },
      "source": [
        "chars = [char for name in names for char in name]\n",
        "freq = nltk.FreqDist(chars)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY82ymMz1HEx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e90687-8063-4fdd-c13b-5339f60a7e4b"
      },
      "source": [
        "freq"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'<': 1536,\n",
              "          '>': 1536,\n",
              "          'a': 2487,\n",
              "          'b': 171,\n",
              "          'c': 539,\n",
              "          'd': 341,\n",
              "          'e': 913,\n",
              "          'f': 37,\n",
              "          'g': 360,\n",
              "          'h': 548,\n",
              "          'i': 944,\n",
              "          'j': 55,\n",
              "          'k': 141,\n",
              "          'l': 617,\n",
              "          'm': 328,\n",
              "          'n': 1081,\n",
              "          'o': 1710,\n",
              "          'p': 552,\n",
              "          'q': 23,\n",
              "          'r': 1704,\n",
              "          's': 2285,\n",
              "          't': 852,\n",
              "          'u': 2123,\n",
              "          'v': 111,\n",
              "          'w': 41,\n",
              "          'x': 85,\n",
              "          'y': 266,\n",
              "          'z': 60})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VnuL9Bf1HFS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a070646-c827-4e3e-c117-5bef6986f23d"
      },
      "source": [
        "print(list(freq.keys()))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<', 'a', 'c', 'h', 'e', 'n', 'o', 's', 'u', 'r', '>', 'd', 'y', 'x', 'b', 'l', 'i', 't', 'p', 'v', 'm', 'g', 'f', 'j', 'k', 'w', 'z', 'q']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkHZnWFN1HFy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd353ec1-e408-400f-abe1-7798cda90814"
      },
      "source": [
        "freq.most_common(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('a', 2487),\n",
              " ('s', 2285),\n",
              " ('u', 2123),\n",
              " ('o', 1710),\n",
              " ('r', 1704),\n",
              " ('<', 1536),\n",
              " ('>', 1536),\n",
              " ('n', 1081),\n",
              " ('i', 944),\n",
              " ('e', 913)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CFqe1cB1HGP"
      },
      "source": [
        "Определим функцию для вычисления условной вероятности символов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C4VP4hR1HGU"
      },
      "source": [
        "l = sum([freq[char] for char in freq])\n",
        "def unigram_prob(char):\n",
        "    return freq[char] / l"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kiiv0vo1HG2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5824ad0-72e8-48a0-cb75-5e2edb65835a"
      },
      "source": [
        "print('p(a) = %1.4f' %unigram_prob('<'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p(a) = 0.0716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pbpj8VLv1HHX"
      },
      "source": [
        "Вычислим условную вероятность каждого символа в зависимости от того, какой символ стоял на предыдущей позиции."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-GW1NZB1HHd"
      },
      "source": [
        "cfreq = nltk.ConditionalFreqDist(nltk.bigrams(chars))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXvcbL1m1HId",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e53d24cd-5fcc-42a3-d105-e8c8b83c6f74"
      },
      "source": [
        "cfreq['a']"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'>': 138,\n",
              "          'a': 11,\n",
              "          'b': 24,\n",
              "          'c': 100,\n",
              "          'd': 36,\n",
              "          'e': 42,\n",
              "          'f': 6,\n",
              "          'g': 40,\n",
              "          'h': 17,\n",
              "          'i': 23,\n",
              "          'j': 5,\n",
              "          'k': 20,\n",
              "          'l': 138,\n",
              "          'm': 68,\n",
              "          'n': 347,\n",
              "          'o': 22,\n",
              "          'p': 89,\n",
              "          'q': 3,\n",
              "          'r': 124,\n",
              "          's': 171,\n",
              "          't': 204,\n",
              "          'u': 791,\n",
              "          'v': 30,\n",
              "          'w': 6,\n",
              "          'x': 12,\n",
              "          'y': 12,\n",
              "          'z': 8})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuV5anvn1HJL"
      },
      "source": [
        "Оценим условные вероятности с помощью MLE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWnDDdJO1HJQ"
      },
      "source": [
        "cprob = nltk.ConditionalProbDist(cfreq, nltk.MLEProbDist)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-q-UONs1HJz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ee2cd97-d251-4a30-b562-7b087d27c6d9"
      },
      "source": [
        "print('p(a a) = %1.4f' %cprob['a'].prob('a'))\n",
        "print('p(a b) = %1.4f' %cprob['a'].prob('b'))\n",
        "print('p(a u) = %1.4f' %cprob['<'].prob('<'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p(a a) = 0.0044\n",
            "p(a b) = 0.0097\n",
            "p(a u) = 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmXTHNpU1HKQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "8acd226a-8bb0-4ac0-8101-2769300fecae"
      },
      "source": [
        "cprob['a'].generate()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'t'"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M80v-kVK1HLO"
      },
      "source": [
        "### Task 1.\n",
        "a. Write a function to generate a dinosaur name of **fixed** length. Use '<' as a start of name symbol.\n",
        "\n",
        "b. Write a function to generate a dinosaur names of any length. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-ZmpvP71HLY"
      },
      "source": [
        "def generate_n_word(n=10):\n",
        "    word = '<'    \n",
        "    while (len(word) <= n):\n",
        "        c = cprob[word[-1]].generate()\n",
        "        if c not in {'<','>'}: word += c        \n",
        "    word += '>'\n",
        "    return word"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJqCN5LE1HLv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e575061d-f59a-4c06-8bf8-2c044b680ba3"
      },
      "source": [
        "generate_n_word()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<lasalliauy>'"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBBT-_pC5j24"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In-qSTog5-Yz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c0f4e8cf-7612-416d-9eb4-56d6a1b78470"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<ausatonimiusagonthapurusasaskiveishos>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpiHvyOwqGi_"
      },
      "source": [
        "## Модели n-грамм для слов\n",
        "(https://nlpforhackers.io/language-models/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7w_ThviqHY7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec0fcfdb-0451-4d0b-ff98-0fa0e3c267ee"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import reuters\n",
        "from nltk import bigrams, trigrams\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "nltk.download('reuters')\n",
        "nltk.download('punkt')\n",
        "!unzip /root/nltk_data/corpora/reuters.zip -d /root/nltk_data/corpora\n",
        "\n",
        "first_sentence = reuters.sents()[0]\n",
        "print (first_sentence) # [u'ASIAN', u'EXPORTERS', u'FEAR', u'DAMAGE', u'FROM' ...\n",
        " \n",
        "# Get the bigrams\n",
        "print (list(bigrams(first_sentence))) # [(u'ASIAN', u'EXPORTERS'), (u'EXPORTERS', u'FEAR'), (u'FEAR', u'DAMAGE'), (u'DAMAGE', u'FROM'), ...\n",
        " \n",
        "# Get the padded bigrams\n",
        "print (list(bigrams(first_sentence, pad_left=True, pad_right=True))) # [(None, u'ASIAN'), (u'ASIAN', u'EXPORTERS'), (u'EXPORTERS', u'FEAR'), (u'FEAR', u'DAMAGE'), (u'DAMAGE', u'FROM'),\n",
        " \n",
        "# Get the trigrams\n",
        "print (list(trigrams(first_sentence))) # [(u'ASIAN', u'EXPORTERS', u'FEAR'), (u'EXPORTERS', u'FEAR', u'DAMAGE'), (u'FEAR', u'DAMAGE', u'FROM'), ...\n",
        " \n",
        "# Get the padded trigrams\n",
        "print (list(trigrams(first_sentence, pad_left=True, pad_right=True))) # [(None, None, u'ASIAN'), (None, u'ASIAN', u'EXPORTERS'), (u'ASIAN', u'EXPORTERS', u'FEAR'), (u'EXPORTERS', u'FEAR', u'DAMAGE'), (u'FEAR', u'DAMAGE', u'FROM') ..."
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "['ASIAN', 'EXPORTERS', 'FEAR', 'DAMAGE', 'FROM', 'U', '.', 'S', '.-', 'JAPAN', 'RIFT', 'Mounting', 'trade', 'friction', 'between', 'the', 'U', '.', 'S', '.', 'And', 'Japan', 'has', 'raised', 'fears', 'among', 'many', 'of', 'Asia', \"'\", 's', 'exporting', 'nations', 'that', 'the', 'row', 'could', 'inflict', 'far', '-', 'reaching', 'economic', 'damage', ',', 'businessmen', 'and', 'officials', 'said', '.']\n",
            "[('ASIAN', 'EXPORTERS'), ('EXPORTERS', 'FEAR'), ('FEAR', 'DAMAGE'), ('DAMAGE', 'FROM'), ('FROM', 'U'), ('U', '.'), ('.', 'S'), ('S', '.-'), ('.-', 'JAPAN'), ('JAPAN', 'RIFT'), ('RIFT', 'Mounting'), ('Mounting', 'trade'), ('trade', 'friction'), ('friction', 'between'), ('between', 'the'), ('the', 'U'), ('U', '.'), ('.', 'S'), ('S', '.'), ('.', 'And'), ('And', 'Japan'), ('Japan', 'has'), ('has', 'raised'), ('raised', 'fears'), ('fears', 'among'), ('among', 'many'), ('many', 'of'), ('of', 'Asia'), ('Asia', \"'\"), (\"'\", 's'), ('s', 'exporting'), ('exporting', 'nations'), ('nations', 'that'), ('that', 'the'), ('the', 'row'), ('row', 'could'), ('could', 'inflict'), ('inflict', 'far'), ('far', '-'), ('-', 'reaching'), ('reaching', 'economic'), ('economic', 'damage'), ('damage', ','), (',', 'businessmen'), ('businessmen', 'and'), ('and', 'officials'), ('officials', 'said'), ('said', '.')]\n",
            "[(None, 'ASIAN'), ('ASIAN', 'EXPORTERS'), ('EXPORTERS', 'FEAR'), ('FEAR', 'DAMAGE'), ('DAMAGE', 'FROM'), ('FROM', 'U'), ('U', '.'), ('.', 'S'), ('S', '.-'), ('.-', 'JAPAN'), ('JAPAN', 'RIFT'), ('RIFT', 'Mounting'), ('Mounting', 'trade'), ('trade', 'friction'), ('friction', 'between'), ('between', 'the'), ('the', 'U'), ('U', '.'), ('.', 'S'), ('S', '.'), ('.', 'And'), ('And', 'Japan'), ('Japan', 'has'), ('has', 'raised'), ('raised', 'fears'), ('fears', 'among'), ('among', 'many'), ('many', 'of'), ('of', 'Asia'), ('Asia', \"'\"), (\"'\", 's'), ('s', 'exporting'), ('exporting', 'nations'), ('nations', 'that'), ('that', 'the'), ('the', 'row'), ('row', 'could'), ('could', 'inflict'), ('inflict', 'far'), ('far', '-'), ('-', 'reaching'), ('reaching', 'economic'), ('economic', 'damage'), ('damage', ','), (',', 'businessmen'), ('businessmen', 'and'), ('and', 'officials'), ('officials', 'said'), ('said', '.'), ('.', None)]\n",
            "[('ASIAN', 'EXPORTERS', 'FEAR'), ('EXPORTERS', 'FEAR', 'DAMAGE'), ('FEAR', 'DAMAGE', 'FROM'), ('DAMAGE', 'FROM', 'U'), ('FROM', 'U', '.'), ('U', '.', 'S'), ('.', 'S', '.-'), ('S', '.-', 'JAPAN'), ('.-', 'JAPAN', 'RIFT'), ('JAPAN', 'RIFT', 'Mounting'), ('RIFT', 'Mounting', 'trade'), ('Mounting', 'trade', 'friction'), ('trade', 'friction', 'between'), ('friction', 'between', 'the'), ('between', 'the', 'U'), ('the', 'U', '.'), ('U', '.', 'S'), ('.', 'S', '.'), ('S', '.', 'And'), ('.', 'And', 'Japan'), ('And', 'Japan', 'has'), ('Japan', 'has', 'raised'), ('has', 'raised', 'fears'), ('raised', 'fears', 'among'), ('fears', 'among', 'many'), ('among', 'many', 'of'), ('many', 'of', 'Asia'), ('of', 'Asia', \"'\"), ('Asia', \"'\", 's'), (\"'\", 's', 'exporting'), ('s', 'exporting', 'nations'), ('exporting', 'nations', 'that'), ('nations', 'that', 'the'), ('that', 'the', 'row'), ('the', 'row', 'could'), ('row', 'could', 'inflict'), ('could', 'inflict', 'far'), ('inflict', 'far', '-'), ('far', '-', 'reaching'), ('-', 'reaching', 'economic'), ('reaching', 'economic', 'damage'), ('economic', 'damage', ','), ('damage', ',', 'businessmen'), (',', 'businessmen', 'and'), ('businessmen', 'and', 'officials'), ('and', 'officials', 'said'), ('officials', 'said', '.')]\n",
            "[(None, None, 'ASIAN'), (None, 'ASIAN', 'EXPORTERS'), ('ASIAN', 'EXPORTERS', 'FEAR'), ('EXPORTERS', 'FEAR', 'DAMAGE'), ('FEAR', 'DAMAGE', 'FROM'), ('DAMAGE', 'FROM', 'U'), ('FROM', 'U', '.'), ('U', '.', 'S'), ('.', 'S', '.-'), ('S', '.-', 'JAPAN'), ('.-', 'JAPAN', 'RIFT'), ('JAPAN', 'RIFT', 'Mounting'), ('RIFT', 'Mounting', 'trade'), ('Mounting', 'trade', 'friction'), ('trade', 'friction', 'between'), ('friction', 'between', 'the'), ('between', 'the', 'U'), ('the', 'U', '.'), ('U', '.', 'S'), ('.', 'S', '.'), ('S', '.', 'And'), ('.', 'And', 'Japan'), ('And', 'Japan', 'has'), ('Japan', 'has', 'raised'), ('has', 'raised', 'fears'), ('raised', 'fears', 'among'), ('fears', 'among', 'many'), ('among', 'many', 'of'), ('many', 'of', 'Asia'), ('of', 'Asia', \"'\"), ('Asia', \"'\", 's'), (\"'\", 's', 'exporting'), ('s', 'exporting', 'nations'), ('exporting', 'nations', 'that'), ('nations', 'that', 'the'), ('that', 'the', 'row'), ('the', 'row', 'could'), ('row', 'could', 'inflict'), ('could', 'inflict', 'far'), ('inflict', 'far', '-'), ('far', '-', 'reaching'), ('-', 'reaching', 'economic'), ('reaching', 'economic', 'damage'), ('economic', 'damage', ','), ('damage', ',', 'businessmen'), (',', 'businessmen', 'and'), ('businessmen', 'and', 'officials'), ('and', 'officials', 'said'), ('officials', 'said', '.'), ('said', '.', None), ('.', None, None)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW3O6-LcrGYp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77895924-710e-4a81-d7ce-52ba89aefeb0"
      },
      "source": [
        "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
        " \n",
        "for sentence in reuters.sents():\n",
        "    for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\n",
        "        model[(w1, w2)][w3] += 1\n",
        " \n",
        " \n",
        "print (model[\"what\", \"the\"][\"economists\"]) # \"economists\" follows \"what the\" 2 times\n",
        "print (model[\"what\", \"the\"][\"nonexistingword\"]) # 0 times\n",
        "print (model[None, None][\"The\"]) # 8839 sentences start with \"The\"\n",
        " \n",
        "# Let's transform the counts to probabilities\n",
        "for w1_w2 in model:\n",
        "    total_count = float(sum(model[w1_w2].values()))\n",
        "    for w3 in model[w1_w2]:\n",
        "        model[w1_w2][w3] /= total_count\n",
        " \n",
        "print (model[\"what\", \"the\"][\"economists\"]) # 0.0434782608696\n",
        "print (model[\"what\", \"the\"][\"nonexistingword\"]) # 0.0\n",
        "print (model[None, None][\"The\"]) # 0.161543241465\n",
        " "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "0\n",
            "8839\n",
            "0.043478260869565216\n",
            "0.0\n",
            "0.16154324146501936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8X-KSIfr1J8"
      },
      "source": [
        "The probability of a sequence is computed using conditional probabilities.\n",
        "The probability of word[i] given word[i-1] and word[i-2] is P(word[i] | word[i-1], word[i-2]) which in our case is equal to: model[(word[i-2], word[i-1])][word[i]]\n",
        "\n",
        "Let’s add the probability computation in the generation script:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hxRPdLhrVKb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aca22e8d-6e3c-4b2d-b338-a88a3defee67"
      },
      "source": [
        "import random\n",
        " \n",
        " \n",
        "text = [None, None]\n",
        "prob = 1.0  # <- Init probability\n",
        " \n",
        "sentence_finished = False\n",
        " \n",
        "while not sentence_finished:\n",
        "    r = random.random()\n",
        "    accumulator = .0\n",
        " \n",
        "    for word in model[tuple(text[-2:])].keys():\n",
        "        accumulator += model[tuple(text[-2:])][word]\n",
        " \n",
        "        if accumulator >= r:\n",
        "            prob *= model[tuple(text[-2:])][word]  # <- Update the probability with the conditional probability of the new word\n",
        "            text.append(word)\n",
        "            break\n",
        " \n",
        "    if text[-2:] == [None, None]:\n",
        "        sentence_finished = True\n",
        " \n",
        "print (\"Probability of text=\", prob)  # <- Print the probability of the text\n",
        "print (' '.join([t for t in text if t]))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of text= 7.316613597257671e-29\n",
            "Hongkong Aircraft Engineering Co , said Turkey has been postponed because \" workers have not been invoked since 1978 , are only about 450 miles east of Bahrain in the money market intervention tender .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB6SH5vhsPor"
      },
      "source": [
        "##Task 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVSWTkQqsaZv"
      },
      "source": [
        "Напишите функцию, которая будет генерировать предложение и оценивать его вероятность. Подсказка: предложение должно заканчиваться соответствующим знаком препинания."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LY1C-_-sjDK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iz0QMOdD1HMK"
      },
      "source": [
        "## Реккурентные нейронные сети (RNN)\n",
        "\n",
        "Исходная последовательность:\n",
        "\n",
        "$x_{1:n} = x_1, x_2, \\ldots, x_n$, $x_i \\in \\mathbb{R}^{d_{in}}$\n",
        "\n",
        "Для каждого входного значения $x_{1:i}$ получаем на выходе $y_i$:\n",
        "\n",
        "$y_i = RNN(x_{1:i})$, $y_i \\in \\mathbb{R}^{d_{out}}$\n",
        "\n",
        "Для всей последовательности $x_{1:n}$:\n",
        "\n",
        "$y_{1:n} = RNN^{*}(x_{1:n})$, $y_i \\in \\mathbb{R}^{d_{out}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O34g-rG21HMN"
      },
      "source": [
        "$R$ - рекурсивная функция активации, зависящая от двух параметров: $x_i$ и $s_{i-1}$ (вектор предыдущего состояния)\n",
        "\n",
        "$RNN^{*}(x_{1:n}, s_0) = y_{1:n}$\n",
        "\n",
        "$y_i = O(s_i) = g(W^{out}[s_{i} ,x_i] +b)$\n",
        "\n",
        "$s_i = R(s_{i-1}, x_i)$\n",
        "\n",
        "$s_i = R(s_{i-1}, x_i) = g(W^{hid}[s_{i-1} ,x_i] +b)$  -- конкатенация $[s_{i-1}, x]$\n",
        "\n",
        "$x_i \\in \\mathbb{R}^{d_{in}}$, $y_i \\in \\mathbb{R}^{ d_{out}}$, $s_i \\in \\mathbb{R}^{d_{hid}}$\n",
        "\n",
        "$W^{hid} \\in \\mathbb{R}^{(d_{in}+d_{out}) \\times d_{hid}}$, $W^{out} \\in \\mathbb{R}^{d_{hid} \\times d_{out}}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RI9dlfCK1HMU"
      },
      "source": [
        "Построим языковую модель на основе RNN с помощью pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gclyau4j1HMc"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pdb\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "torch.set_printoptions(linewidth=200)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVk_vofO1HM0"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "hidden_size = 50"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF4Dp1OK1HNS"
      },
      "source": [
        "Подготовим данные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          0
        ],
        "id": "Q49llCoq1HNV"
      },
      "source": [
        "class DinosDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        with open('dinos.txt') as f:\n",
        "            content = f.read().lower()\n",
        "            self.vocab = sorted(set(content)) + ['<', '>']\n",
        "            self.vocab_size = len(self.vocab)\n",
        "            self.lines = content.splitlines()\n",
        "        self.ch_to_idx = {c:i for i, c in enumerate(self.vocab)}\n",
        "        self.idx_to_ch = {i:c for i, c in enumerate(self.vocab)}\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        line = self.lines[index]\n",
        "        #teacher forcing\n",
        "        x_str = '<' + line \n",
        "        y_str = line + '>' \n",
        "        x = torch.zeros([len(x_str), self.vocab_size], dtype=torch.float)\n",
        "        y = torch.empty(len(x_str), dtype=torch.long)\n",
        "        for i, (x_ch, y_ch) in enumerate(zip(x_str, y_str)):\n",
        "            x[i][self.ch_to_idx[x_ch]] = 1\n",
        "            y[i] = self.ch_to_idx[y_ch]\n",
        "        \n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.lines)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xCx68KK1HNq"
      },
      "source": [
        "trn_ds = DinosDataset()\n",
        "trn_dl = DataLoader(trn_ds, shuffle=True)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4GHhNw21HOG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "4cc4f770-b6da-4ba3-8d41-8cc952cd6a0c"
      },
      "source": [
        "trn_ds.lines[1]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'aardonyx'"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caYYHf741HOh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2a8bfaa-8482-4bd2-bb76-7adb11aa9d70"
      },
      "source": [
        "print(trn_ds.idx_to_ch)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: '\\n', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 27: '<', 28: '>'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhngI6P41HO0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be88f276-32b7-46a0-de90-3b2e8fb5f3a4"
      },
      "source": [
        "trn_ds.vocab_size"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heT6Yt1c1HPL"
      },
      "source": [
        "x, y = trn_ds[1]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "PVidOvMz1HPl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1c4f24d-8af5-4533-fadc-77599e1b910c"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([9, 29])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOoyQP661HP_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc54e47f-9de1-42bd-a399-b71684516237"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([9])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnDCqfhW1HQP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c44d5b1-813a-4f62-f45c-b1586216ae11"
      },
      "source": [
        "y"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  1, 18,  4, 15, 14, 25, 24, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zg4vQkSJ1HQo"
      },
      "source": [
        "Опишем модель, функцию потерь и алгоритм оптимизации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "fiFev9H71HQs"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.i2o = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    def forward(self, h_prev, x):\n",
        "        combined = torch.cat([h_prev, x], dim = 1) # concatenate x and h\n",
        "        h = torch.tanh(self.dropout(self.i2h(combined)))\n",
        "        y = self.i2o(h)\n",
        "        return h, y"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bGJs5pv1HRD"
      },
      "source": [
        "model = RNN(trn_ds.vocab_size, hidden_size, trn_ds.vocab_size).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq9c9Gky1HRk"
      },
      "source": [
        "![rnn](images/dinos3.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "udihoEbb1HRq"
      },
      "source": [
        "def sample(model):\n",
        "    model.eval()\n",
        "    word_size=0\n",
        "    newline_idx = trn_ds.ch_to_idx['>']\n",
        "    with torch.no_grad():\n",
        "        h_prev = torch.zeros([1, hidden_size], dtype=torch.float, device=device)\n",
        "        x = h_prev.new_zeros([1, trn_ds.vocab_size])\n",
        "        start_char_idx = trn_ds.ch_to_idx['<']\n",
        "        indices = [start_char_idx]\n",
        "        x[0, start_char_idx] = 1\n",
        "        predicted_char_idx = start_char_idx\n",
        "        \n",
        "        while predicted_char_idx != newline_idx and word_size != 50:\n",
        "            h_prev, y_pred = model(h_prev, x)\n",
        "            y_softmax_scores = torch.softmax(y_pred, dim=1)\n",
        "            \n",
        "            np.random.seed(np.random.randint(1, 5000))\n",
        "            idx = np.random.choice(np.arange(trn_ds.vocab_size), p=y_softmax_scores.cpu().numpy().ravel())\n",
        "            indices.append(idx)\n",
        "            \n",
        "            x = (y_pred == y_pred.max(1)[0]).float()\n",
        "            \n",
        "            predicted_char_idx = idx\n",
        "            \n",
        "            word_size += 1\n",
        "        \n",
        "        if word_size == 50:\n",
        "            indices.append(newline_idx)\n",
        "    return indices"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "Xvv2iWX21HR9"
      },
      "source": [
        "def print_sample(sample_idxs):\n",
        "    [print(trn_ds.idx_to_ch[x], end ='') for x in sample_idxs]\n",
        "    print()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGCHFxl91HSY"
      },
      "source": [
        "Обучим получившуюся модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "Mi3I-sOd1HSc"
      },
      "source": [
        "def train_one_epoch(model, loss_fn, optimizer):\n",
        "    model.train()\n",
        "    for line_num, (x, y) in enumerate(trn_dl):\n",
        "        loss = 0\n",
        "        optimizer.zero_grad()\n",
        "        h_prev = torch.zeros([1, hidden_size], dtype=torch.float, device=device)\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        for i in range(x.shape[1]):\n",
        "            h_prev, y_pred = model(h_prev, x[:, i])\n",
        "            loss += loss_fn(y_pred, y[:, i])\n",
        "            \n",
        "        if (line_num+1) % 100 == 0:\n",
        "            print_sample(sample(model))\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "-UYREWWS1HSu"
      },
      "source": [
        "def train(model, loss_fn, optimizer, dataset='dinos', epochs=1):\n",
        "    for e in range(1, epochs+1):\n",
        "        print('Epoch:{}'.format(e))\n",
        "        train_one_epoch(model, loss_fn, optimizer)\n",
        "        print()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "ydIB8Xi41HS8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9abeaede-b544-4e04-b63a-db30004be95c"
      },
      "source": [
        "train(model, loss_fn, optimizer, epochs = 10)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1\n",
            "<luiyaauoaodulmauao>\n",
            "<qxctutohtst>\n",
            "<ulrusaurhs>\n",
            "<aulucauras>\n",
            "<thrasausus>\n",
            "<turon>\n",
            "<sntus>\n",
            "<ssarkceuhus>\n",
            "<aaurasturum>\n",
            "<aaurun>\n",
            "<turesor>\n",
            "<sarpsaaupus>\n",
            "<slsaitocos>\n",
            "<gnataosusus>\n",
            "<spnushurus>\n",
            "\n",
            "Epoch:2\n",
            "<tbrocaurus>\n",
            "<agonaonopicsousus>\n",
            "<suricnur>\n",
            "<sprotapaurul>\n",
            "<fuaatobs>\n",
            "<tmlatcp>\n",
            "<ptdrusaurus>\n",
            "<satruaaurus>\n",
            "<snubcoraurus>\n",
            "<aubotuunus>\n",
            "<llosotiurusturis>\n",
            "<atgtcauras>\n",
            "<slcbocaurus>\n",
            "<suris>\n",
            "<ixthsssaurus>\n",
            "\n",
            "Epoch:3\n",
            "<augucesairus>\n",
            "<jaucosmurus>\n",
            "<llsom>\n",
            "<snoosaipaurus>\n",
            "<ucctnasaurus>\n",
            "<anuprurus>\n",
            "<ekurysuus>\n",
            "<aneahsdpurus>\n",
            "<lbiesaurus>\n",
            "<xructsaurus>\n",
            "<zurustaraurus>\n",
            "<eubasacrus>\n",
            "<gcsarsusuus>\n",
            "<llrtouaurus>\n",
            "<hoaisaurus>\n",
            "\n",
            "Epoch:4\n",
            "<snamkcurus>\n",
            "<juntdtssaurus>\n",
            "<snosplrus>\n",
            "<sdthtcaurds>\n",
            "<tmgatdaurus>\n",
            "<stnnusaurus>\n",
            "<tanras>\n",
            "<atetalaurus>\n",
            "<hiataotoxcos>\n",
            "<menonysaurul>\n",
            "<kcescaurus>\n",
            "<lacgopaurus>\n",
            "<pugpstin>\n",
            "<rnytorosbordk>\n",
            "<auatahsnator>\n",
            "\n",
            "Epoch:5\n",
            "<haucotaurus>\n",
            "<llkonuurus>\n",
            "<arraltcuuris>\n",
            "<laidsaurus>\n",
            "<wrtcsiurus>\n",
            "<kvurostasaurus>\n",
            "<fradopapaurus>\n",
            "<ansotesaurus>\n",
            "<kvoosaurus>\n",
            "<eucrmsamaurus>\n",
            "<gmaudaurus>\n",
            "<stnesopuurus>\n",
            "<anianaurus>\n",
            "<augangusaurus>\n",
            "<pucssiurus>\n",
            "\n",
            "Epoch:6\n",
            "<ztgoskurus>\n",
            "<scthucauros>\n",
            "<slebtnrus>\n",
            "<crstngsaurus>\n",
            "<suammansaurus>\n",
            "<snamataurus>\n",
            "<xrucscurus>\n",
            "<kwoosowcaurus>\n",
            "<sltaiosaurus>\n",
            "<arfitaurus>\n",
            "<lanol>\n",
            "<snosserus>\n",
            "<scthtan>\n",
            "<lbiesaurus>\n",
            "<wptdsaurus>\n",
            "\n",
            "Epoch:7\n",
            "<ixonrosaurus>\n",
            "<augucauris>\n",
            "<seebochtatops>\n",
            "<lmrrivturus>\n",
            "<kicruc>\n",
            "<euaesaprus>\n",
            "<gcsantsuurus>\n",
            "<etupysaurus>\n",
            "<lanras>\n",
            "<ubbspaurus>\n",
            "<atcrus>\n",
            "<crronaurus>\n",
            "<lrotanoapturus>\n",
            "<bthacurus>\n",
            "<tciuosaurus>\n",
            "\n",
            "Epoch:8\n",
            "<srgwshsaurus>\n",
            "<etcrotaurum>\n",
            "<ctlrasaurus>\n",
            "<stpkiosaurus>\n",
            "<tanoanter>\n",
            "<tagroaturus>\n",
            "<taotutiurus>\n",
            "<rrgyonsosaurus>\n",
            "<asdtadaurus>\n",
            "<elasaosaurus>\n",
            "<lhurhysaurus>\n",
            "<jccsaurur>\n",
            "<shciethnaurus>\n",
            "<tgsusaurus>\n",
            "<snrrsauras>\n",
            "\n",
            "Epoch:9\n",
            "<akuros>\n",
            "<laurupaurus>\n",
            "<puesosler>\n",
            "<jwsmsourus>\n",
            "<fucsmtcaouaos>\n",
            "<hheris>\n",
            "<nuasourus>\n",
            "<iwrnosaurus>\n",
            "<sauopcauris>\n",
            "<slcatcosaurus>\n",
            "<llorluaurus>\n",
            "<iibpocauras>\n",
            "<lbgeulgesaurus>\n",
            "<stnkoaurus>\n",
            "<prsaeraooh>\n",
            "\n",
            "Epoch:10\n",
            "<euacopaolupaurus>\n",
            "<oucuttonaurus>\n",
            "<prtanaurus>\n",
            "<ercasocaurus>\n",
            "<sanvisator>\n",
            "<eturvsaurus>\n",
            "<lafsaturus>\n",
            "<laidsisaurus>\n",
            "<ugrurliaurus>\n",
            "<pruansaurus>\n",
            "<taisdbiasaurus>\n",
            "<vntaspurus>\n",
            "<lyurossurus>\n",
            "<scolscg>\n",
            "<lbiasaurus>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sseocQG1HTN"
      },
      "source": [
        "def generate_dino(n=50):\n",
        "    word = '<'\n",
        "    for i in range(n):\n",
        "        word += cprob[word[-1]].generate()\n",
        "        if word[-1] == '>':\n",
        "            return word\n",
        "    word += '>'\n",
        "    return word"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rqU5Mxh1HTg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e67ac54-0f70-4111-ae8b-8a848135e688"
      },
      "source": [
        "nn.RNN"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.nn.modules.rnn.RNN"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-dctLty1HT0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dae3852-876a-42c9-bcfa-248c05931140"
      },
      "source": [
        "for i in range(10):\n",
        "    print(generate_dino())"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<mblisatorochipalohintedatixieos>\n",
            "<hinonggrururusandiceloseluptruros>\n",
            "<morua>\n",
            "<husaurushosurus>\n",
            "<lisanaurodosadodn>\n",
            "<husatiaurunonimitorau>\n",
            "<s>\n",
            "<pengosan>\n",
            "<egas>\n",
            "<kiaus>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMVLZtS31HUF"
      },
      "source": [
        "### Task 2.\n",
        "Rewrite the sampling function to generate pangrams (words that contain each character of the alphabet only once)\n",
        "\n",
        "### Task 3.\n",
        "Rewrite the sampling function so that it would be possible to change the sampling temperature\n",
        "\n",
        "### Task 4.\n",
        "Implement the beam search for sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7J29hyD1HUI"
      },
      "source": [
        "#a = y_softmax_scores.cpu().numpy().ravel()"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cESnEczm1HUX"
      },
      "source": [
        "def equalize_probs_sqrt(in_vector):\n",
        "    out_vector = np.zeros_like(in_vector)\n",
        "    for i, el in enumerate(in_vector):\n",
        "        out_vector[i] = np.math.sqrt(el)\n",
        "\n",
        "    return out_vector / sum(out_vector)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSSLWGYf1HUn"
      },
      "source": [
        "#equalize_probs_sqrt(vec)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYY7T0PI1HU3"
      },
      "source": [
        "def sample_hotter(model):\n",
        "    model.eval()\n",
        "    word_size=0\n",
        "    newline_idx = trn_ds.ch_to_idx['>']\n",
        "    with torch.no_grad():\n",
        "        h_prev = torch.zeros([1, hidden_size], dtype=torch.float, device=device)\n",
        "        x = h_prev.new_zeros([1, trn_ds.vocab_size])\n",
        "        start_char_idx = trn_ds.ch_to_idx['<']\n",
        "        indices = [start_char_idx]\n",
        "        x[0, start_char_idx] = 1\n",
        "        predicted_char_idx = start_char_idx\n",
        "        \n",
        "        while predicted_char_idx != newline_idx and word_size != 50:\n",
        "            h_prev, y_pred = model(h_prev, x)\n",
        "            y_softmax_scores = torch.softmax(y_pred, dim=1)\n",
        "            \n",
        "            np.random.seed(np.random.randint(1, 5000))\n",
        "            \n",
        "            next_prob_vector = equalize_probs_sqrt(y_softmax_scores.cpu().numpy().ravel())\n",
        "            idx = np.random.choice(np.arange(trn_ds.vocab_size), p=next_prob_vector)\n",
        "            indices.append(idx)\n",
        "            \n",
        "            x = (y_pred == y_pred.max(1)[0]).float()\n",
        "            \n",
        "            predicted_char_idx = idx\n",
        "            \n",
        "            word_size += 1\n",
        "        \n",
        "        if word_size == 50:\n",
        "            indices.append(newline_idx)\n",
        "    return indices"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbgAzOPH1HVM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9f87de4-bc93-4d77-dcaf-29a4f7a29956"
      },
      "source": [
        "print_sample(sample_hotter(model))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<yrucrttoauruz>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJ84UeWS1HVc"
      },
      "source": [
        "# Reference\n",
        "\n",
        "1. Sampling in  RNN: https://nlp.stanford.edu/blog/maximum-likelihood-decoding-with-rnns-the-good-the-bad-and-the-ugly/\n",
        "2. Coursera course (main source): https://github.com/furkanu/deeplearning.ai-pytorch/tree/master/5-%20Sequence%20Models\n",
        "3. Coursera course (main source): https://github.com/Kulbear/deep-learning-coursera/blob/master/Sequence%20Models/Dinosaurus%20Island%20--%20Character%20level%20language%20model%20final%20-%20v3.ipynb\n",
        "4. LSTM: http://colah.github.io/posts/2015-08-Understanding-LSTMs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpJ5oOw71HVf"
      },
      "source": [
        "## Named Entity Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN2y-8bg1HVi"
      },
      "source": [
        "\n",
        "#### Постановка задачи «sequence labeling»:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiuhtx931HVm"
      },
      "source": [
        "\n",
        "* Дан корпус текстов $D$\n",
        "* Каждый текст представляет собой последовательность токенов\n",
        "* Каждому токену присвоена метка из некоторого множества $V$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2itmS0jz1HVn"
      },
      "source": [
        "В зависимости от множества меток $V$ получаем разные типы подзадач. Например:\n",
        "* если $V$ - множество частей речи, то это задача ***POS***-теггинга\n",
        "* если $V$ - множество типов именованных сущностей, то это задача ***NER***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ojQmOTw1HVq"
      },
      "source": [
        "Именованная сущность - любой фрагмент текста, обозначающий некоторый интересный объект."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tCKeBrf1HVs"
      },
      "source": [
        "#### Conditional Random Fields"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVlxNw7U1HVv"
      },
      "source": [
        "***Conditional Random Field*** - развитие метода Марковских случайных полей. Графовая модель, которая используется для представления совместных распределений набора нескольких случайных переменных. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s51FX51t1HVz"
      },
      "source": [
        "Особенности модели ***CRF***:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79S68rHZ1HV2"
      },
      "source": [
        "* Качество сильно зависит от выбора признаков\n",
        "\n",
        "* Один из лучших методов для ***NER*** и ***POS***-теггинга\n",
        "\n",
        "* Долго обучается\n",
        "\n",
        "* Хорошо работает в связке с рекуррентными нейросетями, моделирует совместное распределение на всей последовательности выходов сети одновременно"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dslKEuEc1HV5"
      },
      "source": [
        "#### Архитектура BiLSTM-CRF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l82FscQH1HV8"
      },
      "source": [
        "В данной модели для каждого слова вычисляется его векторное представление на основе символьного состава слова, предобученных векоторных представлений (***Word2Vec***, ***FastText***, ***GloVe***), а также других признаков (***POS***-тег, роль в предложении и т.д.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwiDECZ91HWA"
      },
      "source": [
        "![representation](images/word_representation_model.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bQYkj1d1HWH"
      },
      "source": [
        "Общая схема модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SYOwhoY1HWL"
      },
      "source": [
        "![bilstm_crf](images/bilstm_crf_model.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4_c_wQN1HWO"
      },
      "source": [
        "Основные шаги алгоритма:\n",
        "* Получить предобученные эмбеддинги слов коллекции (***word2vec***, ***GloVe***)\n",
        "$$$$\n",
        "* Обучить символьные эмбеддинги (***char-BiLSTM***, ***char-CNN***)\n",
        "$$$$\n",
        "* Составить для каждого слова морфологические/синтаксические признаки (***POS***-тег, роль в предложении и т.п.)\n",
        "$$$$\n",
        "* Объединить всё это и подать на вход основной сети (***BiLSTM***)\n",
        "$$$$\n",
        "* Выходы $h_t$ для всех слов предложения подавать на вход классификатору,\n",
        "который будет предсказывать NER-тег (***SoftMax***, ***CRF***)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoCRtqo-1HWT"
      },
      "source": [
        "#!pip3 install http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv-8Qbwv1HWj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d7429f5-d39b-4095-ca48-97c56813bb1c"
      },
      "source": [
        "!pip3 install torchvision"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.10.0+cu102)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.9.0+cu102)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchvision) (3.7.4.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YIOIGvb1HW4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd85d0b8-c558-4c1b-a82e-97b664b9bcce"
      },
      "source": [
        "!pip3 install torchtext"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.9.0+cu102)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.62.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2021.5.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hXfLWz31HXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ecb93fe-50b1-4426-c2c4-42589513f454"
      },
      "source": [
        "!pip3 install natasha"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting natasha\n",
            "  Downloading natasha-1.4.0-py3-none-any.whl (34.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 34.4 MB 29 kB/s \n",
            "\u001b[?25hCollecting ipymarkup>=0.8.0\n",
            "  Downloading ipymarkup-0.9.0-py3-none-any.whl (14 kB)\n",
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 2.4 MB/s \n",
            "\u001b[?25hCollecting navec>=0.9.0\n",
            "  Downloading navec-0.10.0-py3-none-any.whl (23 kB)\n",
            "Collecting slovnet>=0.3.0\n",
            "  Downloading slovnet-0.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting razdel>=0.5.0\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Collecting yargy>=0.14.0\n",
            "  Downloading yargy-0.15.0-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 95 kB/s \n",
            "\u001b[?25hCollecting intervaltree>=3\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from navec>=0.9.0->natasha) (1.19.5)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.6.2)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 52.2 MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Building wheels for collected packages: intervaltree\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26119 sha256=c33c358c31d44df05dc2718d4f8a9265f6e6b72804c478f28d573b9352cafe34\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/85/bd/1001cbb46dcfb71c2001cd7401c6fb250392f22a81ce3722f7\n",
            "Successfully built intervaltree\n",
            "Installing collected packages: pymorphy2-dicts-ru, dawg-python, razdel, pymorphy2, navec, intervaltree, yargy, slovnet, ipymarkup, natasha\n",
            "  Attempting uninstall: intervaltree\n",
            "    Found existing installation: intervaltree 2.1.0\n",
            "    Uninstalling intervaltree-2.1.0:\n",
            "      Successfully uninstalled intervaltree-2.1.0\n",
            "Successfully installed dawg-python-0.7.2 intervaltree-3.1.0 ipymarkup-0.9.0 natasha-1.4.0 navec-0.10.0 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844 razdel-0.5.0 slovnet-0.5.0 yargy-0.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5RccXOW1HXa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acab24af-4756-4ca5-dd36-12c41c66edc0"
      },
      "source": [
        "!python3 -m spacy download en_core_web_sm"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.62.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuDGYuHN1HXs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e10b7873-8419-4f80-d504-635e073f6f77"
      },
      "source": [
        "!pip install html5lib"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from html5lib) (1.15.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from html5lib) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9vMOimj1HX_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24c03ad2-624b-4279-e30d-3c690ff2f095"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/synalp/NER/master/corpus/CoNLL-2003/eng.testa"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-22 19:25:51--  https://raw.githubusercontent.com/synalp/NER/master/corpus/CoNLL-2003/eng.testa\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 827012 (808K) [text/plain]\n",
            "Saving to: ‘eng.testa’\n",
            "\n",
            "eng.testa           100%[===================>] 807.63K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2021-09-22 19:25:51 (17.5 MB/s) - ‘eng.testa’ saved [827012/827012]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfVWhLo01HYV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c2bfbc6-26f3-4b7d-bf50-d0769ecc47a5"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/synalp/NER/master/corpus/CoNLL-2003/eng.testb"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-22 19:26:04--  https://raw.githubusercontent.com/synalp/NER/master/corpus/CoNLL-2003/eng.testb\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 748096 (731K) [text/plain]\n",
            "Saving to: ‘eng.testb’\n",
            "\n",
            "eng.testb           100%[===================>] 730.56K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-09-22 19:26:04 (16.4 MB/s) - ‘eng.testb’ saved [748096/748096]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmHqVBWu1HYk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53e24f31-c1d9-48b4-c3ee-f1bcfeab74c4"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/synalp/NER/master/corpus/CoNLL-2003/eng.train"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-22 19:26:07--  https://raw.githubusercontent.com/synalp/NER/master/corpus/CoNLL-2003/eng.train\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3281528 (3.1M) [text/plain]\n",
            "Saving to: ‘eng.train’\n",
            "\n",
            "eng.train           100%[===================>]   3.13M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2021-09-22 19:26:07 (45.0 MB/s) - ‘eng.train’ saved [3281528/3281528]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOjXY3151HY1"
      },
      "source": [
        "!mkdir datasets && mv eng.* datasets/"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcS3ocoT1HZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25309cc8-bea7-42d8-8c6c-d4e380b2c512"
      },
      "source": [
        "!wget https://worksheets.codalab.org/rest/bundles/0x15a09c8f74f94a20bec0b68a2e6703b3/contents/blob/ && mkdir embeddings && mv index.html embeddings/glove.6B.100d.txt"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-22 19:26:19--  https://worksheets.codalab.org/rest/bundles/0x15a09c8f74f94a20bec0b68a2e6703b3/contents/blob/\n",
            "Resolving worksheets.codalab.org (worksheets.codalab.org)... 13.68.212.115\n",
            "Connecting to worksheets.codalab.org (worksheets.codalab.org)|13.68.212.115|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2021-09-22 19:26:20 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_OvRsio1HZT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "711395c4-f915-4c71-ac6e-460f51f9c8d5"
      },
      "source": [
        "!git clone https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Sequence-Labeling"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'a-PyTorch-Tutorial-to-Sequence-Labeling'...\n",
            "remote: Enumerating objects: 139, done.\u001b[K\n",
            "remote: Total 139 (delta 0), reused 0 (delta 0), pack-reused 139\u001b[K\n",
            "Receiving objects: 100% (139/139), 6.49 MiB | 19.25 MiB/s, done.\n",
            "Resolving deltas: 100% (68/68), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCBLwuyN1HZh"
      },
      "source": [
        "!mkdir conll2003 && cp datasets/eng.testa conll2003/eng.testa.txt && cp datasets/eng.testb conll2003/eng.testb.txt && cp datasets/eng.train conll2003/eng.train.txt"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GnUvEDw1HZx"
      },
      "source": [
        "!mkdir .data && mv conll2003 .data/"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjCLgtUc1HZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e5f9f45-9842-4980-f265-70901c40692d"
      },
      "source": [
        "!git clone https://github.com/kolloldas/torchnlp"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'torchnlp'...\n",
            "remote: Enumerating objects: 247, done.\u001b[K\n",
            "remote: Total 247 (delta 0), reused 0 (delta 0), pack-reused 247\u001b[K\n",
            "Receiving objects: 100% (247/247), 2.13 MiB | 11.14 MiB/s, done.\n",
            "Resolving deltas: 100% (120/120), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5CE8RnW1HaK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17fda5af-a859-468b-ea17-d9609d520874"
      },
      "source": [
        "!cd torchnlp && pip3 install -r requirements.txt && python3 setup.py install"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+git://github.com/kolloldas/text.git (from -r requirements.txt (line 4))\n",
            "  Cloning git://github.com/kolloldas/text.git to /tmp/pip-req-build-zux4f_rg\n",
            "  Running command git clone -q git://github.com/kolloldas/text.git /tmp/pip-req-build-zux4f_rg\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.62.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (3.6.4)\n",
            "Collecting pytest-mock\n",
            "  Downloading pytest_mock-3.6.1-py3-none-any.whl (12 kB)\n",
            "Collecting pytest-pythonpath\n",
            "  Downloading pytest-pythonpath-0.7.3.tar.gz (4.5 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.3.0->-r requirements.txt (line 4)) (2.23.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->-r requirements.txt (line 9)) (1.10.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->-r requirements.txt (line 9)) (0.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->-r requirements.txt (line 9)) (57.4.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->-r requirements.txt (line 9)) (8.9.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->-r requirements.txt (line 9)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->-r requirements.txt (line 9)) (21.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from pytest->-r requirements.txt (line 9)) (1.15.0)\n",
            "Collecting pytest\n",
            "  Downloading pytest-6.2.5-py3-none-any.whl (280 kB)\n",
            "\u001b[K     |████████████████████████████████| 280 kB 7.5 MB/s \n",
            "\u001b[?25h  Downloading pytest-6.2.4-py3-none-any.whl (280 kB)\n",
            "\u001b[K     |████████████████████████████████| 280 kB 47.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest->-r requirements.txt (line 9)) (4.8.1)\n",
            "  Downloading pytest-6.2.3-py3-none-any.whl (280 kB)\n",
            "\u001b[K     |████████████████████████████████| 280 kB 54.1 MB/s \n",
            "\u001b[?25h  Downloading pytest-6.2.2-py3-none-any.whl (280 kB)\n",
            "\u001b[K     |████████████████████████████████| 280 kB 34.0 MB/s \n",
            "\u001b[?25h  Downloading pytest-6.2.1-py3-none-any.whl (279 kB)\n",
            "\u001b[K     |████████████████████████████████| 279 kB 40.8 MB/s \n",
            "\u001b[?25h  Downloading pytest-6.2.0-py3-none-any.whl (279 kB)\n",
            "\u001b[K     |████████████████████████████████| 279 kB 58.5 MB/s \n",
            "\u001b[?25h  Downloading pytest-6.1.2-py3-none-any.whl (272 kB)\n",
            "\u001b[K     |████████████████████████████████| 272 kB 50.1 MB/s \n",
            "\u001b[?25h  Downloading pytest-6.1.1-py3-none-any.whl (272 kB)\n",
            "\u001b[K     |████████████████████████████████| 272 kB 44.4 MB/s \n",
            "\u001b[?25h  Downloading pytest-6.1.0-py3-none-any.whl (272 kB)\n",
            "\u001b[K     |████████████████████████████████| 272 kB 47.5 MB/s \n",
            "\u001b[?25h  Downloading pytest-6.0.2-py3-none-any.whl (270 kB)\n",
            "\u001b[K     |████████████████████████████████| 270 kB 42.3 MB/s \n",
            "\u001b[?25h  Downloading pytest-6.0.1-py3-none-any.whl (270 kB)\n",
            "\u001b[K     |████████████████████████████████| 270 kB 46.9 MB/s \n",
            "\u001b[?25h  Downloading pytest-6.0.0-py3-none-any.whl (270 kB)\n",
            "\u001b[K     |████████████████████████████████| 270 kB 37.0 MB/s \n",
            "\u001b[?25h  Downloading pytest-5.4.3-py3-none-any.whl (248 kB)\n",
            "\u001b[K     |████████████████████████████████| 248 kB 42.5 MB/s \n",
            "\u001b[?25h  Downloading pytest-5.4.2-py3-none-any.whl (247 kB)\n",
            "\u001b[K     |████████████████████████████████| 247 kB 47.3 MB/s \n",
            "\u001b[?25h  Downloading pytest-5.4.1-py3-none-any.whl (246 kB)\n",
            "\u001b[K     |████████████████████████████████| 246 kB 48.4 MB/s \n",
            "\u001b[?25h  Downloading pytest-5.4.0-py3-none-any.whl (247 kB)\n",
            "\u001b[K     |████████████████████████████████| 247 kB 47.4 MB/s \n",
            "\u001b[?25h  Downloading pytest-5.3.5-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 46.9 MB/s \n",
            "\u001b[?25h  Downloading pytest-5.3.4-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 46.5 MB/s \n",
            "\u001b[?25h  Downloading pytest-5.3.3-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 48.6 MB/s \n",
            "\u001b[?25h  Downloading pytest-5.3.2-py3-none-any.whl (234 kB)\n",
            "\u001b[K     |████████████████████████████████| 234 kB 35.5 MB/s \n",
            "\u001b[?25h  Downloading pytest-5.3.1-py3-none-any.whl (233 kB)\n",
            "\u001b[K     |████████████████████████████████| 233 kB 47.5 MB/s \n",
            "\u001b[?25h  Downloading pytest-5.3.0-py3-none-any.whl (233 kB)\n",
            "\u001b[K     |████████████████████████████████| 233 kB 47.5 MB/s \n",
            "\u001b[?25h  Downloading pytest-5.2.4-py3-none-any.whl (227 kB)\n",
            "\u001b[K     |████████████████████████████████| 227 kB 48.3 MB/s \n",
            "\u001b[?25h  Downloading pytest-5.2.3-py3-none-any.whl (227 kB)\n",
            "\u001b[K     |████████████████████████████████| 227 kB 50.7 MB/s \n",
            "\u001b[?25h  Downloading pytest-5.2.2-py3-none-any.whl (227 kB)\n",
            "\u001b[K     |████████████████████████████████| 227 kB 48.8 MB/s \n",
            "\u001b[?25h  Downloading pytest-5.2.1-py3-none-any.whl (226 kB)\n",
            "\u001b[K     |████████████████████████████████| 226 kB 49.7 MB/s \n",
            "\u001b[?25h  Downloading pytest-5.2.0-py3-none-any.whl (226 kB)\n",
            "\u001b[K     |████████████████████████████████| 226 kB 3.6 MB/s \n",
            "\u001b[?25h  Downloading pytest-5.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[K     |████████████████████████████████| 224 kB 46.8 MB/s \n",
            "\u001b[?25h  Downloading pytest-5.1.2-py3-none-any.whl (224 kB)\n",
            "\u001b[K     |████████████████████████████████| 224 kB 45.5 MB/s \n",
            "\u001b[?25h  Downloading pytest-5.1.1-py3-none-any.whl (223 kB)\n",
            "\u001b[K     |████████████████████████████████| 223 kB 41.3 MB/s \n",
            "\u001b[?25h  Downloading pytest-5.1.0-py3-none-any.whl (223 kB)\n",
            "\u001b[K     |████████████████████████████████| 223 kB 44.8 MB/s \n",
            "\u001b[?25h  Downloading pytest-5.0.1-py3-none-any.whl (221 kB)\n",
            "\u001b[K     |████████████████████████████████| 221 kB 35.8 MB/s \n",
            "\u001b[?25h  Downloading pytest-5.0.0-py3-none-any.whl (221 kB)\n",
            "\u001b[K     |████████████████████████████████| 221 kB 48.9 MB/s \n",
            "\u001b[?25hINFO: pip is looking at multiple versions of <Python from Requires-Python> to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of pytest-mock to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting pytest-mock\n",
            "  Downloading pytest_mock-3.6.0-py3-none-any.whl (12 kB)\n",
            "  Downloading pytest_mock-3.5.1-py3-none-any.whl (12 kB)\n",
            "  Downloading pytest_mock-3.5.0-py3-none-any.whl (12 kB)\n",
            "  Downloading pytest_mock-3.4.0-py3-none-any.whl (11 kB)\n",
            "  Downloading pytest_mock-3.3.1-py3-none-any.whl (11 kB)\n",
            "  Downloading pytest_mock-3.3.0-py3-none-any.whl (11 kB)\n",
            "  Downloading pytest_mock-3.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.3.0->-r requirements.txt (line 4)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.3.0->-r requirements.txt (line 4)) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.3.0->-r requirements.txt (line 4)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.3.0->-r requirements.txt (line 4)) (2.10)\n",
            "Building wheels for collected packages: torchtext, pytest-pythonpath\n",
            "  Building wheel for torchtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchtext: filename=torchtext-0.3.0-py3-none-any.whl size=57531 sha256=5b9929e569b81b0111870114d6defb1b101295fe3419b59c748bdf7bf99dece8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-a7t14ovj/wheels/39/39/6d/724914c8f8f5496b2dc411bfce1594e2357cc15265bf65cd4f\n",
            "  Building wheel for pytest-pythonpath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytest-pythonpath: filename=pytest_pythonpath-0.7.3-py3-none-any.whl size=3065 sha256=4c842a35fe3539d9af2a5cd9bff9a347b25d8fd40a5ec32796c2a6e50be95659\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/b0/19/dd3cabde905d31afde9347bcc99595ae3eccc024c2bb18f67c\n",
            "Successfully built torchtext pytest-pythonpath\n",
            "Installing collected packages: torchtext, pytest-pythonpath, pytest-mock\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.10.0\n",
            "    Uninstalling torchtext-0.10.0:\n",
            "      Successfully uninstalled torchtext-0.10.0\n",
            "Successfully installed pytest-mock-3.2.0 pytest-pythonpath-0.7.3 torchtext-0.3.0\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating torchnlp.egg-info\n",
            "writing torchnlp.egg-info/PKG-INFO\n",
            "writing dependency_links to torchnlp.egg-info/dependency_links.txt\n",
            "writing top-level names to torchnlp.egg-info/top_level.txt\n",
            "writing manifest file 'torchnlp.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'torchnlp.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/torchnlp\n",
            "copying torchnlp/chunk.py -> build/lib/torchnlp\n",
            "copying torchnlp/ner.py -> build/lib/torchnlp\n",
            "copying torchnlp/__init__.py -> build/lib/torchnlp\n",
            "creating build/lib/torchnlp/tasks\n",
            "copying torchnlp/tasks/__init__.py -> build/lib/torchnlp/tasks\n",
            "creating build/lib/torchnlp/data\n",
            "copying torchnlp/data/conll.py -> build/lib/torchnlp/data\n",
            "copying torchnlp/data/nyt.py -> build/lib/torchnlp/data\n",
            "copying torchnlp/data/__init__.py -> build/lib/torchnlp/data\n",
            "copying torchnlp/data/inputs.py -> build/lib/torchnlp/data\n",
            "creating build/lib/torchnlp/modules\n",
            "copying torchnlp/modules/outputs.py -> build/lib/torchnlp/modules\n",
            "copying torchnlp/modules/crf.py -> build/lib/torchnlp/modules\n",
            "copying torchnlp/modules/normalization.py -> build/lib/torchnlp/modules\n",
            "copying torchnlp/modules/__init__.py -> build/lib/torchnlp/modules\n",
            "creating build/lib/torchnlp/common\n",
            "copying torchnlp/common/info.py -> build/lib/torchnlp/common\n",
            "copying torchnlp/common/model.py -> build/lib/torchnlp/common\n",
            "copying torchnlp/common/cmd.py -> build/lib/torchnlp/common\n",
            "copying torchnlp/common/hparams.py -> build/lib/torchnlp/common\n",
            "copying torchnlp/common/prefs.py -> build/lib/torchnlp/common\n",
            "copying torchnlp/common/__init__.py -> build/lib/torchnlp/common\n",
            "copying torchnlp/common/train.py -> build/lib/torchnlp/common\n",
            "copying torchnlp/common/evaluation.py -> build/lib/torchnlp/common\n",
            "creating build/lib/torchnlp/tasks/sequence_tagging\n",
            "copying torchnlp/tasks/sequence_tagging/transformer_tagger.py -> build/lib/torchnlp/tasks/sequence_tagging\n",
            "copying torchnlp/tasks/sequence_tagging/bilstm_tagger.py -> build/lib/torchnlp/tasks/sequence_tagging\n",
            "copying torchnlp/tasks/sequence_tagging/main.py -> build/lib/torchnlp/tasks/sequence_tagging\n",
            "copying torchnlp/tasks/sequence_tagging/__init__.py -> build/lib/torchnlp/tasks/sequence_tagging\n",
            "copying torchnlp/tasks/sequence_tagging/tagger.py -> build/lib/torchnlp/tasks/sequence_tagging\n",
            "creating build/lib/torchnlp/modules/transformer\n",
            "copying torchnlp/modules/transformer/sublayers.py -> build/lib/torchnlp/modules/transformer\n",
            "copying torchnlp/modules/transformer/main.py -> build/lib/torchnlp/modules/transformer\n",
            "copying torchnlp/modules/transformer/__init__.py -> build/lib/torchnlp/modules/transformer\n",
            "copying torchnlp/modules/transformer/layers.py -> build/lib/torchnlp/modules/transformer\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/torchnlp\n",
            "creating build/bdist.linux-x86_64/egg/torchnlp/tasks\n",
            "creating build/bdist.linux-x86_64/egg/torchnlp/tasks/sequence_tagging\n",
            "copying build/lib/torchnlp/tasks/sequence_tagging/transformer_tagger.py -> build/bdist.linux-x86_64/egg/torchnlp/tasks/sequence_tagging\n",
            "copying build/lib/torchnlp/tasks/sequence_tagging/bilstm_tagger.py -> build/bdist.linux-x86_64/egg/torchnlp/tasks/sequence_tagging\n",
            "copying build/lib/torchnlp/tasks/sequence_tagging/main.py -> build/bdist.linux-x86_64/egg/torchnlp/tasks/sequence_tagging\n",
            "copying build/lib/torchnlp/tasks/sequence_tagging/__init__.py -> build/bdist.linux-x86_64/egg/torchnlp/tasks/sequence_tagging\n",
            "copying build/lib/torchnlp/tasks/sequence_tagging/tagger.py -> build/bdist.linux-x86_64/egg/torchnlp/tasks/sequence_tagging\n",
            "copying build/lib/torchnlp/tasks/__init__.py -> build/bdist.linux-x86_64/egg/torchnlp/tasks\n",
            "creating build/bdist.linux-x86_64/egg/torchnlp/data\n",
            "copying build/lib/torchnlp/data/conll.py -> build/bdist.linux-x86_64/egg/torchnlp/data\n",
            "copying build/lib/torchnlp/data/nyt.py -> build/bdist.linux-x86_64/egg/torchnlp/data\n",
            "copying build/lib/torchnlp/data/__init__.py -> build/bdist.linux-x86_64/egg/torchnlp/data\n",
            "copying build/lib/torchnlp/data/inputs.py -> build/bdist.linux-x86_64/egg/torchnlp/data\n",
            "creating build/bdist.linux-x86_64/egg/torchnlp/modules\n",
            "copying build/lib/torchnlp/modules/outputs.py -> build/bdist.linux-x86_64/egg/torchnlp/modules\n",
            "copying build/lib/torchnlp/modules/crf.py -> build/bdist.linux-x86_64/egg/torchnlp/modules\n",
            "copying build/lib/torchnlp/modules/normalization.py -> build/bdist.linux-x86_64/egg/torchnlp/modules\n",
            "creating build/bdist.linux-x86_64/egg/torchnlp/modules/transformer\n",
            "copying build/lib/torchnlp/modules/transformer/sublayers.py -> build/bdist.linux-x86_64/egg/torchnlp/modules/transformer\n",
            "copying build/lib/torchnlp/modules/transformer/main.py -> build/bdist.linux-x86_64/egg/torchnlp/modules/transformer\n",
            "copying build/lib/torchnlp/modules/transformer/__init__.py -> build/bdist.linux-x86_64/egg/torchnlp/modules/transformer\n",
            "copying build/lib/torchnlp/modules/transformer/layers.py -> build/bdist.linux-x86_64/egg/torchnlp/modules/transformer\n",
            "copying build/lib/torchnlp/modules/__init__.py -> build/bdist.linux-x86_64/egg/torchnlp/modules\n",
            "creating build/bdist.linux-x86_64/egg/torchnlp/common\n",
            "copying build/lib/torchnlp/common/info.py -> build/bdist.linux-x86_64/egg/torchnlp/common\n",
            "copying build/lib/torchnlp/common/model.py -> build/bdist.linux-x86_64/egg/torchnlp/common\n",
            "copying build/lib/torchnlp/common/cmd.py -> build/bdist.linux-x86_64/egg/torchnlp/common\n",
            "copying build/lib/torchnlp/common/hparams.py -> build/bdist.linux-x86_64/egg/torchnlp/common\n",
            "copying build/lib/torchnlp/common/prefs.py -> build/bdist.linux-x86_64/egg/torchnlp/common\n",
            "copying build/lib/torchnlp/common/__init__.py -> build/bdist.linux-x86_64/egg/torchnlp/common\n",
            "copying build/lib/torchnlp/common/train.py -> build/bdist.linux-x86_64/egg/torchnlp/common\n",
            "copying build/lib/torchnlp/common/evaluation.py -> build/bdist.linux-x86_64/egg/torchnlp/common\n",
            "copying build/lib/torchnlp/chunk.py -> build/bdist.linux-x86_64/egg/torchnlp\n",
            "copying build/lib/torchnlp/ner.py -> build/bdist.linux-x86_64/egg/torchnlp\n",
            "copying build/lib/torchnlp/__init__.py -> build/bdist.linux-x86_64/egg/torchnlp\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torchnlp/tasks/sequence_tagging/transformer_tagger.py to transformer_tagger.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torchnlp/tasks/sequence_tagging/bilstm_tagger.py to bilstm_tagger.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torchnlp/tasks/sequence_tagging/main.py to main.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torchnlp/tasks/sequence_tagging/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torchnlp/tasks/sequence_tagging/tagger.py to tagger.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torchnlp/tasks/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torchnlp/data/conll.py to conll.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torchnlp/data/nyt.py to nyt.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torchnlp/data/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torchnlp/data/inputs.py to inputs.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torchnlp/modules/outputs.py to outputs.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torchnlp/modules/crf.py to crf.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torchnlp/modules/normalization.py to normalization.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torchnlp/modules/transformer/sublayers.py to sublayers.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torchnlp/modules/transformer/main.py to main.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torchnlp/modules/transformer/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torchnlp/modules/transformer/layers.py to layers.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torchnlp/modules/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torchnlp/common/info.py to info.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torchnlp/common/model.py to model.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torchnlp/common/cmd.py to cmd.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torchnlp/common/hparams.py to hparams.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torchnlp/common/prefs.py to prefs.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torchnlp/common/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torchnlp/common/train.py to train.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torchnlp/common/evaluation.py to evaluation.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torchnlp/chunk.py to chunk.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torchnlp/ner.py to ner.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/torchnlp/__init__.py to __init__.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying torchnlp.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying torchnlp.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying torchnlp.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying torchnlp.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/torchnlp-0.1.0-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing torchnlp-0.1.0-py3.7.egg\n",
            "Copying torchnlp-0.1.0-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
            "Adding torchnlp 0.1.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/torchnlp-0.1.0-py3.7.egg\n",
            "Processing dependencies for torchnlp==0.1.0\n",
            "Finished processing dependencies for torchnlp==0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gF119Ux1HaY"
      },
      "source": [
        "#### Spacy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdW6ADlQ1Hab"
      },
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "from collections import Counter\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMd8o_m91Haq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2941744c-e3e0-42ae-8215-bc6e7589b906"
      },
      "source": [
        "doc = nlp('European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices')\n",
        "print([(X.text, X.label_) for X in doc.ents])"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('European', 'NORP'), ('Google', 'ORG'), ('$5.1 billion', 'MONEY'), ('Wednesday', 'DATE')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w5bFX_Q1Ha5"
      },
      "source": [
        "Выкачаем статью и найдём в ней именованные сущности, выведем их число:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qmUrWD11Ha8"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import re\n",
        "def url_to_string(url):\n",
        "    res = requests.get(url)\n",
        "    html = res.text\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    for script in soup([\"script\", \"style\", 'aside']):\n",
        "        script.extract()\n",
        "    return \" \".join(re.split(r'[\\n\\t]+', soup.get_text()))"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUNyG8Hr1HbL"
      },
      "source": [
        "ny_bb = url_to_string('https://www.nytimes.com/2018/08/13/us/politics/peter-strzok-fired-fbi.html?hp&action=click&pgtype=Homepage&clickSource=story-heading&module=first-column-region&region=top-news&WT.nav=top-news')\n",
        "article = nlp(ny_bb)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGgwNFyS1Hba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "799eb44b-75f6-4e27-ea03-33997a404acb"
      },
      "source": [
        "len(article.ents)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "153"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f4Z7r441Hb4"
      },
      "source": [
        "Выведем число встреченных сущностей каждого типа:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq7w_s_b1Hb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "008bb7aa-d4fa-4056-aac6-37c1efed4f05"
      },
      "source": [
        "labels = [x.label_ for x in article.ents]\n",
        "Counter(labels)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'CARDINAL': 3,\n",
              "         'DATE': 23,\n",
              "         'GPE': 9,\n",
              "         'LOC': 1,\n",
              "         'NORP': 2,\n",
              "         'ORDINAL': 1,\n",
              "         'ORG': 37,\n",
              "         'PERSON': 77})"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3_EFC3V1HcK"
      },
      "source": [
        "Выведем текст с подсвеченными сущностями разных типов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzwaNm9z1HcM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2fc7658f-0ded-4081-a14f-6038a6bb95fe"
      },
      "source": [
        "sentences = [x for x in article.sents]\n",
        "displacy.render(nlp(str(sentences)), jupyter=True, style='ent')"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">[ \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    F.B.I.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " Agent \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Peter Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", Who Criticized Trump in \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Texts\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", Is Fired - \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    The New York Times\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "    SectionsSEARCHSkip to contentSkip to site indexPoliticsToday’s PaperPolitics|F.B.I. Agent \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Peter Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", Who Criticized Trump in \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Texts\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ",, Is Firedhttps://www.nytimes.com/2018/08/13/us/politics/peter-strzok-fired-fbi.htmlAdvertisementContinue reading the main storySupported \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    byContinue\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " reading the main storyF.B.I. Agent \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Peter Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", Who Criticized Trump in \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Texts\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", Is \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    FiredPeter Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", a top \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    F.B.I.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " counterintelligence agent who was taken off the special counsel investigation after his disparaging texts about President \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Trump\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " were uncovered, was fired., Credit..., \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    T.J. Kirkpatrick\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " for \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    The New York TimesBy Adam\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " Goldman and \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Michael S. SchmidtAug.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    13\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2018WASHINGTON\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ", — \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Peter Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", the \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    F.B.I.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " senior counterintelligence agent who disparaged President \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Trump\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " in inflammatory text messages and helped oversee the \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Hillary Clinton\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " email and \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Russia\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " investigations, has been fired for violating bureau policies, Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "’s lawyer said \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Monday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              "., Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Trump\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " and his allies seized on the texts — exchanged during the \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2016\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " campaign with a former \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    F.B.I.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " lawyer, \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Lisa Page\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " — in assailing the \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Russia\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " investigation as an illegitimate “witch hunt.”, Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", who rose over \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    20 years\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " at the \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    F.B.I.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " to become one of its most experienced counterintelligence agents, was a key figure in \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the early months\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " of the inquiry., Along with writing the texts, Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " was accused of sending a highly sensitive search warrant to his personal email account., The \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    F.B.I.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " had been under immense political pressure by Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Trump\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " to dismiss Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", who was removed \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    last summer\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " from the staff of the special counsel, \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Robert S. Mueller III.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", The president has repeatedly denounced Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " in posts on Twitter, and on \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Monday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " expressed satisfaction that he had been sacked., Mr., \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Trump\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", ’s victory traces back to \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    June\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", when Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "’s conduct was laid out in a wide-ranging inspector general’s report on how the \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    F.B.I.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " handled the investigation of \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Hillary Clinton\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", ’s emails in the run-up to the \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2016\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " election., The report was critical of Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "’s conduct in sending the texts, and the bureau’s \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Office of Professional Responsibility\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " said that Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " should be suspended for \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    60 days\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " and demoted., Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " had testified before the \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    House\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " in \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    July\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " about how he had not allowed his political views to interfere with the investigations he was overseeing., But Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "’s lawyer said the deputy director of the \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    F.B.I.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    David Bowdich\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", had overruled \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the Office of Professional Responsibility\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " and fired Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "., A spokeswoman for the \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    F.B.I.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " did not respond to a message seeking comment about why Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " was dismissed rather than demoted., Firing Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", however, removes a favorite target of Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Trump\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " from the ranks of the \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    F.B.I.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " and gives Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bowdich\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " and the \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    F.B.I.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " director, \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Christopher A. Wray\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", a chance to move beyond the president’s ire., \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Aitan Goelman\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "’s lawyer, denounced his client’s dismissal., “The decision to fire Special Agent Strzok is not only a departure from typical bureau practice, but also contradicts Director \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Wray\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "’s testimony to \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Congress\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " and his assurances that the \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    F.B.I.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " intended to follow its regular process in this and all personnel matters,” Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Goelman\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " said., “This decision should be deeply troubling to all \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Americans\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              ",” Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Goelman\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " added., “A lengthy investigation and multiple rounds of congressional testimony failed to produce a shred of evidence that Special Agent Strzok’s personal views ever affected his work.”Mr., Strzok’s text exchanges with Ms. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Page\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " demonstrated animosity toward Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Trump\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "., In one, Ms. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Page\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " asks: \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Trump\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " is “not ever going to become president, right?, Right?!”, Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " responds: “No., No he won’t., We’ll stop it.”, The inspector general, who uncovered the messages, found no evidence that the pair imposed their political views on their investigative decisions but cited that exchange as “not only indicative of a biased state of mind, but, even more seriously, implies a willingness to take official action to impact the presidential candidate’s electoral prospects., ”The, report by the inspector general, \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Michael E. Horowitz\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", that preceded Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "’s firing not only criticized his conduct in sending the texts but also his use of personal email accounts to handle sensitive information., In addition, the inspector general criticized Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "’s decision not to move swiftly to examine new emails related to the \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Clinton\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " investigation \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    just weeks\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " before the \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    2016\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " election., Mr., \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Horowitz\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " said in his report that he was “deeply troubled” by the text messages., \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Hundreds\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " exchanged \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    over months\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " were found in which the pair disparaged Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Trump\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " and, to a lesser extent, Mrs. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Clinton\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", exchanged work gossip and bantered., On Twitter, Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " said he was “deeply saddened by this decision,” adding, “It has been an honor to serve my country and work with the fine men and women of the FBI.”Mr., Strzok became emblematic of Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Trump\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "’s unfounded assertions that a so-called deep state of bureaucrats opposed to him was undermining his presidency., Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Trump\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " contended that Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " targeted the president and accused Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " of being “treasonous” and a “disgrace.”, Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " told lawmakers that he never leaked information about the \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Russia\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " inquiry, which could have upended the election and hurt Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Trump\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", ’s chances of becoming president., After Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Horowitz\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " uncovered the texts, Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Mueller\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", who had by then taken over the investigation, removed Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " from his team., He was reassigned to the \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    F.B.I.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "’s human resources division., Ms. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Page\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", who had left Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Mueller\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "’s team before the discovery of the text messages, quit the \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    F.B.I.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    May.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              ", The inspector general’s report also took issue with the reaction by Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " and other \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    F.B.I.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " officials to the discovery of possible new evidence in the \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Clinton\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " investigation, known internally as \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Midyear Exam\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              ", in late September 2016 on a laptop that belonged to the disgraced politician \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Anthony D. Weiner\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", the husband of a top \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Clinton\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " aide., At the time, Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " was in the early stages of investigating whether any \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Trump\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " associates had conspired with \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Russia\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              "’s interference in the presidential election, and \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    nearly a month\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " passed before, agents and analysts began to act on the emails found on Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Weiner\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "’s laptop., Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Horowitz\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " could not rule out that Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " had slow-walked the examination of the new emails to help Mrs. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Clinton\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "’s presidential bid., “Under, these circumstances, we did not have confidence that \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "’s decision to prioritize the \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Russia\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " investigation over following up on the \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Midyear\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              "-related investigative lead discovered on the \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Weiner\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " laptop was free from bias,” he wrote., The delays were merely the “result of bureaucratic snafus,” Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "’s lawyer wrote \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    last month\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    USA\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Today\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              "., But the justifications for the delay were “unpersuasive” and had “far-reaching consequences,” the inspector general said., \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    James B. Comey\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", the former \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    F.B.I.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " director, has told investigators that if he had known about the emails earlier, it might have influenced his decision to alert \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Congress\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " to their existence \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    days\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " before the election., In addition, the inspector general said that Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " had forwarded a proposed search warrant to his personal email account., The inspector general said the email, which included a draft of the search warrant affidavit, contained information that appeared to be under seal., In a heated congressional hearing \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    last month\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " expressed “significant regret” for the texts and rebutted the president’s attacks on the \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Russia\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " inquiry., “This investigation is not politically motivated; it is not a witch hunt; it is not a hoax,” he said., Mr., Strzok’s dismissal was not unexpected., He is the \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    second\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
              "</mark>\n",
              " senior \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    F.B.I.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " agent to be fired as a result of the inspector general’s investigation., In \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    March\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Andrew G. McCabe\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", the former deputy director, was fired after the inspector general repeatedly faulted him for misleading investigators., The firing was politically motivated, Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    McCabe\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " has said, as an effort to discredit him as a witness in the special counsel investigation., Both men were fired before they were eligible for their pension and health benefits., Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Strzok\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    48\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", a graduate of \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Georgetown University\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", served as an officer in the \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Army\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " before he joined the \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    F.B.I.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " He held several key positions in the \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    F.B.I.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", eventually becoming a top deputy in the counterintelligence division., He handled many important espionage cases including \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    one\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " involving a former \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    C.I.A.\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " officer suspected of working for \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    China\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " and a group of \n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Russian\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " spies who had been working undercover in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the United States\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              "., \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    AdvertisementContinue\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " reading the main storySite \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    IndexSite Information Navigation\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", © 2021 , \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    The New York Times\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              ", CompanyNYTCoContact UsAccessibilityWork with usAdvertiseT Brand StudioYour Ad ChoicesPrivacy PolicyTerms of ServiceTerms of SaleSite MapCanadaInternationalHelpSubscriptions]</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC8XCdrZ1Hcg"
      },
      "source": [
        "### Natasha"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTqIzWSB1Hcj"
      },
      "source": [
        "import natasha"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-GP2fLk1Hcy"
      },
      "source": [
        "l = natasha.MoneyExtractor"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7uNa5dC1HdE"
      },
      "source": [
        "#l('я живу в Москве, но иногда езжу в Питер')"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E1tAyYU1HeP"
      },
      "source": [
        "#### LSTM-CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whMQQwUs1HeR"
      },
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.append('./a-PyTorch-Tutorial-to-Sequence-Labeling')\n",
        "\n",
        "from models import LM_LSTM_CRF, ViterbiLoss\n",
        "from utils import *\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from datasets import WCDataset\n",
        "from inference import ViterbiDecoder\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnNYtWq61Hec"
      },
      "source": [
        "#!touch ./a-PyTorch-Tutorial-to-Sequence-Labeling/__init__.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05mCaaN51Hel",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46afe8a9-3aad-40b6-e059-e9dab197e8fb"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-22 19:31:55--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-09-22 19:31:55--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-09-22 19:31:56--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.08MB/s    in 2m 40s  \n",
            "\n",
            "2021-09-22 19:34:36 (5.14 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61LAfAHY_QC1"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('glove.6B.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('.')"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfczMS321Hex"
      },
      "source": [
        "# Data parameters\n",
        "task = 'ner'  # tagging task, to choose column in CoNLL 2003 dataset\n",
        "train_file = './datasets/eng.train'  # path to training data\n",
        "val_file = './datasets/eng.testa'  # path to validation data\n",
        "test_file = './datasets/eng.testb'  # path to test data\n",
        "emb_file = './glove.6B.100d.txt'  # path to pre-trained word embeddings\n",
        "min_word_freq = 5  # threshold for word frequency\n",
        "min_char_freq = 1  # threshold for character frequency\n",
        "caseless = True  # lowercase everything?\n",
        "expand_vocab = True  # expand model's input vocabulary to the pre-trained embeddings' vocabulary?\n",
        "\n",
        "# Model parameters\n",
        "char_emb_dim = 30  # character embedding size\n",
        "with open(emb_file, 'r') as f:\n",
        "    word_emb_dim = len(f.readline().split(' ')) - 1  # word embedding size\n",
        "word_rnn_dim = 300  # word RNN size\n",
        "char_rnn_dim = 300  # character RNN size\n",
        "char_rnn_layers = 1  # number of layers in character RNN\n",
        "word_rnn_layers = 1  # number of layers in word RNN\n",
        "highway_layers = 1  # number of layers in highway network\n",
        "dropout = 0.5  # dropout\n",
        "fine_tune_word_embeddings = False  # fine-tune pre-trained word embeddings?\n",
        "\n",
        "# Training parameters\n",
        "start_epoch = 0  # start at this epoch\n",
        "batch_size = 10  # batch size\n",
        "lr = 0.015  # learning rate\n",
        "lr_decay = 0.05  # decay learning rate by this amount\n",
        "momentum = 0.9  # momentum\n",
        "workers = 1  # number of workers for loading data in the DataLoader\n",
        "epochs = 10  # number of epochs to run without early-stopping\n",
        "grad_clip = 5.  # clip gradients at this value\n",
        "print_freq = 100  # print training or validation status every __ batches\n",
        "best_f1 = 0.  # F1 score to start with\n",
        "checkpoint = None  # path to model checkpoint, None if none\n",
        "\n",
        "tag_ind = 1 if task == 'pos' else 3  # choose column in CoNLL 2003 dataset\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUQr-K-S1HfA"
      },
      "source": [
        "def train(train_loader, model, lm_criterion, crf_criterion, optimizer, epoch, vb_decoder):\n",
        "    \"\"\"\n",
        "    Performs one epoch's training.\n",
        "    :param train_loader: DataLoader for training data\n",
        "    :param model: model\n",
        "    :param lm_criterion: cross entropy loss layer\n",
        "    :param crf_criterion: viterbi loss layer\n",
        "    :param optimizer: optimizer\n",
        "    :param epoch: epoch number\n",
        "    :param vb_decoder: viterbi decoder (to decode and find F1 score)\n",
        "    \"\"\"\n",
        "\n",
        "    model.train()  # training mode enables dropout\n",
        "\n",
        "    batch_time = AverageMeter()  # forward prop. + back prop. time per batch\n",
        "    data_time = AverageMeter()  # data loading time per batch\n",
        "    ce_losses = AverageMeter()  # cross entropy loss\n",
        "    vb_losses = AverageMeter()  # viterbi loss\n",
        "    f1s = AverageMeter()  # f1 score\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    # Batches\n",
        "    for i, (wmaps, cmaps_f, cmaps_b, cmarkers_f, cmarkers_b, tmaps, wmap_lengths, cmap_lengths) in enumerate(\n",
        "            train_loader):\n",
        "\n",
        "        data_time.update(time.time() - start)\n",
        "\n",
        "        max_word_len = max(wmap_lengths.tolist())\n",
        "        max_char_len = max(cmap_lengths.tolist())\n",
        "\n",
        "        # Reduce batch's padded length to maximum in-batch sequence\n",
        "        # This saves some compute on nn.Linear layers (RNNs are unaffected, since they don't compute over the pads)\n",
        "        wmaps = wmaps[:, :max_word_len].to(device)\n",
        "        cmaps_f = cmaps_f[:, :max_char_len].to(device)\n",
        "        cmaps_b = cmaps_b[:, :max_char_len].to(device)\n",
        "        cmarkers_f = cmarkers_f[:, :max_word_len].to(device)\n",
        "        cmarkers_b = cmarkers_b[:, :max_word_len].to(device)\n",
        "        tmaps = tmaps[:, :max_word_len].to(device)\n",
        "        wmap_lengths = wmap_lengths.to(device)\n",
        "        cmap_lengths = cmap_lengths.to(device)\n",
        "\n",
        "        # Forward prop.\n",
        "        crf_scores, lm_f_scores, lm_b_scores, wmaps_sorted, tmaps_sorted, wmap_lengths_sorted, _, __ = model(cmaps_f,\n",
        "                                                                                                             cmaps_b,\n",
        "                                                                                                             cmarkers_f,\n",
        "                                                                                                             cmarkers_b,\n",
        "                                                                                                             wmaps,\n",
        "                                                                                                             tmaps,\n",
        "                                                                                                             wmap_lengths,\n",
        "                                                                                                             cmap_lengths)\n",
        "\n",
        "        # LM loss\n",
        "\n",
        "        # We don't predict the next word at the pads or <end> tokens\n",
        "        # We will only predict at [dunston, checks, in] among [dunston, checks, in, <end>, <pad>, <pad>, ...]\n",
        "        # So, prediction lengths are word sequence lengths - 1\n",
        "        lm_lengths = wmap_lengths_sorted - 1\n",
        "        lm_lengths = lm_lengths.tolist()\n",
        "\n",
        "        # Remove scores at timesteps we won't predict at\n",
        "        # pack_padded_sequence is a good trick to do this (see dynamic_rnn.py, where we explore this)\n",
        "        #lm_f_scores, _ = pack_padded_sequence(lm_f_scores, lm_lengths, batch_first=True)\n",
        "        #lm_b_scores, _ = pack_padded_sequence(lm_b_scores, lm_lengths, batch_first=True)\n",
        "\n",
        "        # For the forward sequence, targets are from the second word onwards, up to <end>\n",
        "        # (timestep -> target) ...dunston -> checks, ...checks -> in, ...in -> <end>\n",
        "        lm_f_targets = wmaps_sorted[:, 1:]\n",
        "        #lm_f_targets, _ = pack_padded_sequence(lm_f_targets, lm_lengths, batch_first=True)\n",
        "\n",
        "        # For the backward sequence, targets are <end> followed by all words except the last word\n",
        "        # ...notsnud -> <end>, ...skcehc -> dunston, ...ni -> checks\n",
        "        lm_b_targets = torch.cat(\n",
        "            [torch.LongTensor([word_map['<end>']] * wmaps_sorted.size(0)).unsqueeze(1).to(device), wmaps_sorted], dim=1)\n",
        "        #lm_b_targets, _ = pack_padded_sequence(lm_b_targets, lm_lengths, batch_first=True)\n",
        "\n",
        "        # Calculate loss\n",
        "        ce_loss = lm_criterion(lm_f_scores, lm_f_targets) + lm_criterion(lm_b_scores, lm_b_targets)\n",
        "        vb_loss = crf_criterion(crf_scores, tmaps_sorted, wmap_lengths_sorted)\n",
        "        loss = ce_loss + vb_loss\n",
        "\n",
        "        # Back prop.\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        if grad_clip is not None:\n",
        "            clip_gradient(optimizer, grad_clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # Viterbi decode to find accuracy / f1\n",
        "        decoded = vb_decoder.decode(crf_scores.to(\"cpu\"), wmap_lengths_sorted.to(\"cpu\"))\n",
        "\n",
        "        # Remove timesteps we won't predict at, and also <end> tags, because to predict them would be cheating\n",
        "        decoded, _ = pack_padded_sequence(decoded, lm_lengths, batch_first=True)\n",
        "        tmaps_sorted = tmaps_sorted % vb_decoder.tagset_size  # actual target indices (see create_input_tensors())\n",
        "        tmaps_sorted, _ = pack_padded_sequence(tmaps_sorted, lm_lengths, batch_first=True)\n",
        "\n",
        "        # F1\n",
        "        f1 = f1_score(tmaps_sorted.to(\"cpu\").numpy(), decoded.numpy(), average='macro')\n",
        "\n",
        "        # Keep track of metrics\n",
        "        ce_losses.update(ce_loss.item(), sum(lm_lengths))\n",
        "        vb_losses.update(vb_loss.item(), crf_scores.size(0))\n",
        "        batch_time.update(time.time() - start)\n",
        "        f1s.update(f1, sum(lm_lengths))\n",
        "\n",
        "        start = time.time()\n",
        "\n",
        "        # Print training status\n",
        "        if i % print_freq == 0:\n",
        "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "                  'Batch Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Data Load Time {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
        "                  'CE Loss {ce_loss.val:.4f} ({ce_loss.avg:.4f})\\t'\n",
        "                  'VB Loss {vb_loss.val:.4f} ({vb_loss.avg:.4f})\\t'\n",
        "                  'F1 {f1.val:.3f} ({f1.avg:.3f})'.format(epoch, i, len(train_loader),\n",
        "                                                          batch_time=batch_time,\n",
        "                                                          data_time=data_time, ce_loss=ce_losses,\n",
        "                                                          vb_loss=vb_losses, f1=f1s))"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI8yNYYP1HfR"
      },
      "source": [
        "def validate(val_loader, model, crf_criterion, vb_decoder):\n",
        "    \"\"\"\n",
        "    Performs one epoch's validation.\n",
        "    :param val_loader: DataLoader for validation data\n",
        "    :param model: model\n",
        "    :param crf_criterion: viterbi loss layer\n",
        "    :param vb_decoder: viterbi decoder\n",
        "    :return: validation F1 score\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    batch_time = AverageMeter()\n",
        "    vb_losses = AverageMeter()\n",
        "    f1s = AverageMeter()\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    for i, (wmaps, cmaps_f, cmaps_b, cmarkers_f, cmarkers_b, tmaps, wmap_lengths, cmap_lengths) in enumerate(\n",
        "            val_loader):\n",
        "\n",
        "        max_word_len = max(wmap_lengths.tolist())\n",
        "        max_char_len = max(cmap_lengths.tolist())\n",
        "\n",
        "        # Reduce batch's padded length to maximum in-batch sequence\n",
        "        # This saves some compute on nn.Linear layers (RNNs are unaffected, since they don't compute over the pads)\n",
        "        wmaps = wmaps[:, :max_word_len].to(device)\n",
        "        cmaps_f = cmaps_f[:, :max_char_len].to(device)\n",
        "        cmaps_b = cmaps_b[:, :max_char_len].to(device)\n",
        "        cmarkers_f = cmarkers_f[:, :max_word_len].to(device)\n",
        "        cmarkers_b = cmarkers_b[:, :max_word_len].to(device)\n",
        "        tmaps = tmaps[:, :max_word_len].to(device)\n",
        "        wmap_lengths = wmap_lengths.to(device)\n",
        "        cmap_lengths = cmap_lengths.to(device)\n",
        "\n",
        "        # Forward prop.\n",
        "        crf_scores, wmaps_sorted, tmaps_sorted, wmap_lengths_sorted, _, __ = model(cmaps_f,\n",
        "                                                                                   cmaps_b,\n",
        "                                                                                   cmarkers_f,\n",
        "                                                                                   cmarkers_b,\n",
        "                                                                                   wmaps,\n",
        "                                                                                   tmaps,\n",
        "                                                                                   wmap_lengths,\n",
        "                                                                                   cmap_lengths)\n",
        "\n",
        "        # Viterbi / CRF layer loss\n",
        "        vb_loss = crf_criterion(crf_scores, tmaps_sorted, wmap_lengths_sorted)\n",
        "\n",
        "        # Viterbi decode to find accuracy / f1\n",
        "        decoded = vb_decoder.decode(crf_scores.to(\"cpu\"), wmap_lengths_sorted.to(\"cpu\"))\n",
        "\n",
        "        # Remove timesteps we won't predict at, and also <end> tags, because to predict them would be cheating\n",
        "        decoded, _ = pack_padded_sequence(decoded, (wmap_lengths_sorted - 1).tolist(), batch_first=True)\n",
        "        tmaps_sorted = tmaps_sorted % vb_decoder.tagset_size  # actual target indices (see create_input_tensors())\n",
        "        tmaps_sorted, _ = pack_padded_sequence(tmaps_sorted, (wmap_lengths_sorted - 1).tolist(), batch_first=True)\n",
        "\n",
        "        # f1\n",
        "        f1 = f1_score(tmaps_sorted.to(\"cpu\").numpy(), decoded.numpy(), average='macro')\n",
        "\n",
        "        # Keep track of metrics\n",
        "        vb_losses.update(vb_loss.item(), crf_scores.size(0))\n",
        "        f1s.update(f1, sum((wmap_lengths_sorted - 1).tolist()))\n",
        "        batch_time.update(time.time() - start)\n",
        "\n",
        "        start = time.time()\n",
        "\n",
        "        if i % print_freq == 0:\n",
        "            print('Validation: [{0}/{1}]\\t'\n",
        "                  'Batch Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'VB Loss {vb_loss.val:.4f} ({vb_loss.avg:.4f})\\t'\n",
        "                  'F1 Score {f1.val:.3f} ({f1.avg:.3f})\\t'.format(i, len(val_loader), batch_time=batch_time,\n",
        "                                                                  vb_loss=vb_losses, f1=f1s))\n",
        "\n",
        "    print(\n",
        "        '\\n * LOSS - {vb_loss.avg:.3f}, F1 SCORE - {f1.avg:.3f}\\n'.format(vb_loss=vb_losses,\n",
        "                                                                          f1=f1s))\n",
        "\n",
        "    return f1s.avg"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tfz8w3o01Hfg"
      },
      "source": [
        "def main_func():\n",
        "    \"\"\"\n",
        "    Training and validation.\n",
        "    \"\"\"\n",
        "    global best_f1, epochs_since_improvement, checkpoint, start_epoch, word_map, char_map, tag_map\n",
        "\n",
        "    # Read training and validation data\n",
        "    train_words, train_tags = read_words_tags(train_file, tag_ind, caseless)\n",
        "    val_words, val_tags = read_words_tags(val_file, tag_ind, caseless)\n",
        "\n",
        "    # Initialize model or load checkpoint\n",
        "    if checkpoint is not None:\n",
        "        checkpoint = torch.load(checkpoint)\n",
        "        model = checkpoint['model']\n",
        "        optimizer = checkpoint['optimizer']\n",
        "        word_map = checkpoint['word_map']\n",
        "        lm_vocab_size = checkpoint['lm_vocab_size']\n",
        "        tag_map = checkpoint['tag_map']\n",
        "        char_map = checkpoint['char_map']\n",
        "        start_epoch = checkpoint['epoch'] + 1\n",
        "        best_f1 = checkpoint['f1']\n",
        "    else:\n",
        "        word_map, char_map, tag_map = create_maps(train_words + val_words, train_tags + val_tags, min_word_freq,\n",
        "                                                  min_char_freq)  # create word, char, tag maps\n",
        "        embeddings, word_map, lm_vocab_size = load_embeddings(emb_file, word_map,\n",
        "                                                              expand_vocab)  # load pre-trained embeddings\n",
        "\n",
        "        model = LM_LSTM_CRF(tagset_size=len(tag_map),\n",
        "                            charset_size=len(char_map),\n",
        "                            char_emb_dim=char_emb_dim,\n",
        "                            char_rnn_dim=char_rnn_dim,\n",
        "                            char_rnn_layers=char_rnn_layers,\n",
        "                            vocab_size=len(word_map),\n",
        "                            lm_vocab_size=lm_vocab_size,\n",
        "                            word_emb_dim=word_emb_dim,\n",
        "                            word_rnn_dim=word_rnn_dim,\n",
        "                            word_rnn_layers=word_rnn_layers,\n",
        "                            dropout=dropout,\n",
        "                            highway_layers=highway_layers).to(device)\n",
        "        model.init_word_embeddings(embeddings.to(device))  # initialize embedding layer with pre-trained embeddings\n",
        "        model.fine_tune_word_embeddings(fine_tune_word_embeddings)  # fine-tune\n",
        "        optimizer = optim.SGD(params=filter(lambda p: p.requires_grad, model.parameters()), lr=lr, momentum=momentum)\n",
        "\n",
        "    # Loss functions\n",
        "    lm_criterion = nn.CrossEntropyLoss().to(device)\n",
        "    crf_criterion = ViterbiLoss(tag_map).to(device)\n",
        "\n",
        "    # Since the language model's vocab is restricted to in-corpus indices, encode training/val with only these!\n",
        "    # word_map might have been expanded, and in-corpus words eliminated due to low frequency might still be added because\n",
        "    # they were in the pre-trained embeddings\n",
        "    temp_word_map = {k: v for k, v in word_map.items() if v <= word_map['<unk>']}\n",
        "    train_inputs = create_input_tensors(train_words, train_tags, temp_word_map, char_map,\n",
        "                                        tag_map)\n",
        "    val_inputs = create_input_tensors(val_words, val_tags, temp_word_map, char_map, tag_map)\n",
        "\n",
        "    # DataLoaders\n",
        "    train_loader = torch.utils.data.DataLoader(WCDataset(*train_inputs), batch_size=batch_size, shuffle=True,\n",
        "                                               num_workers=workers, pin_memory=False)\n",
        "    val_loader = torch.utils.data.DataLoader(WCDataset(*val_inputs), batch_size=batch_size, shuffle=True,\n",
        "                                             num_workers=workers, pin_memory=False)\n",
        "\n",
        "    # Viterbi decoder (to find accuracy during validation)\n",
        "    vb_decoder = ViterbiDecoder(tag_map)\n",
        "\n",
        "    # Epochs\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "\n",
        "        # One epoch's training\n",
        "        train(train_loader=train_loader,\n",
        "              model=model,\n",
        "              lm_criterion=lm_criterion,\n",
        "              crf_criterion=crf_criterion,\n",
        "              optimizer=optimizer,\n",
        "              epoch=epoch,\n",
        "              vb_decoder=vb_decoder)\n",
        "\n",
        "        # One epoch's validation\n",
        "        val_f1 = validate(val_loader=val_loader,\n",
        "                          model=model,\n",
        "                          crf_criterion=crf_criterion,\n",
        "                          vb_decoder=vb_decoder)\n",
        "\n",
        "        # Did validation F1 score improve?\n",
        "        is_best = val_f1 > best_f1\n",
        "        best_f1 = max(val_f1, best_f1)\n",
        "        if not is_best:\n",
        "            epochs_since_improvement += 1\n",
        "            print(\"\\nEpochs since improvement: %d\\n\" % (epochs_since_improvement,))\n",
        "        else:\n",
        "            epochs_since_improvement = 0\n",
        "\n",
        "        # Save checkpoint\n",
        "        save_checkpoint(epoch, model, optimizer, val_f1, word_map, char_map, tag_map, lm_vocab_size, is_best)\n",
        "\n",
        "        # Decay learning rate every epoch\n",
        "        adjust_learning_rate(optimizer, lr / (1 + (epoch + 1) * lr_decay))"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzzHHMSo1Hfq"
      },
      "source": [
        "#main_func()"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjmWlhoU1Hf2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}